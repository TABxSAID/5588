{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "023d46d6",
   "metadata": {},
   "source": [
    "# CS 5588 — Week 1: Hands-On Lab\n",
    "## Mini-RAG Pipeline: Embeddings → Retrieval → Grounded Generation\n",
    "\n",
    "**Goals:**\n",
    "- Generate semantic embeddings using a Transformer-based encoder\n",
    "- Build a vector index for fast similarity search\n",
    "- Retrieve top-k relevant document chunks\n",
    "- Inject retrieved context into an LLM prompt for grounded generation\n",
    "\n",
    "**Workflow:** GitHub → Colab → Hugging Face → Vector Store (FAISS / Chroma) → LLM\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121c3a04",
   "metadata": {},
   "source": [
    "### GenAI Systems Context (Mini-RAG)\n",
    "This lab implements a **mini Retrieval-Augmented Generation (RAG)** pipeline:\n",
    "- A **Transformer encoder** produces semantic embeddings\n",
    "- A **vector index (FAISS)** enables fast retrieval\n",
    "- Retrieved context is what a downstream **LLM** would use for grounded generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef4bef7",
   "metadata": {},
   "source": [
    "## Step 1 — Environment Setup\n",
    "Install required libraries. This may take ~1 minute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee7fd505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets sentence-transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b733062a",
   "metadata": {},
   "source": [
    "## Step 2 — Load Dataset & Model from Hugging Face Hub\n",
    "We use a lightweight news dataset and a sentence embedding model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af3f5079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 documents\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "dataset = load_dataset(\"ag_news\", split=\"train[:200]\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "texts = dataset[\"text\"]\n",
    "\n",
    "print(f\"Loaded {len(texts)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790e6a14",
   "metadata": {},
   "source": [
    "## Step 3 — Create Embeddings\n",
    "These vectors represent semantic meaning and enable retrieval before generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1982665e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83755e592eee4d3dbc16d5c89d7b5435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (200, 384)\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(texts, show_progress_bar=True)\n",
    "print('Embedding shape:', embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6911831",
   "metadata": {},
   "source": [
    "## Step 4 — Build a Vector Index (FAISS)\n",
    "This simulates the retrieval layer in RAG systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbca6730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index size: 200\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(np.array(embeddings))\n",
    "print('Index size:', index.ntotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8df57f",
   "metadata": {},
   "source": [
    "## Step 5 — Retrieval Function\n",
    "Search for documents related to a query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "552f1272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, k=3):\n",
    "    q_emb = model.encode([query])\n",
    "    distances, indices = index.search(np.array(q_emb), k)\n",
    "    return [texts[int(i)] for i in indices[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37f5c85",
   "metadata": {},
   "source": [
    "## Step 6 — Try It!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "281ea456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"U.K.'s NHS taps Gartner to help plan \\\\$9B IT overhaul LONDON -- The U.K.'s National Health Service (NHS) has tapped IT researcher Gartner Inc. to provide market intelligence services as the health organization forges ahead with a mammoth, 5 billion (\\\\$9.2 billion) project to upgrade its information technology infrastructure.\",\n",
       " 'UK Scientists Allowed to Clone Human Embryos (Reuters) Reuters - British scientists said on Wednesday\\\\they had received permission to clone human embryos for medical\\\\research, in what they believe to be the first such license to\\\\be granted in Europe.',\n",
       " 'Coming to The Rescue Got a unique problem? Not to worry: you can find a financial planner for every specialized need']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"artificial intelligence in healthcare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e5eb92",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "In 1–2 sentences, explain how embeddings enable retrieval before generation in GenAI systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07833156-0731-401f-a51f-31c8084748f4",
   "metadata": {},
   "source": [
    "<span style=\"color: #16ac9f\"> **Embeddings are able to represent textual information in a dense numerical form to encode semantic meaning in a way that allows a system to retrieve relevant information from a set of documents using vector space semantic search rather than keyword-based search. This helps to retrieve specific information that can be used in a generative model to produce correct outputs.**<span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c783cddf-1659-48ab-bbd0-5fa548bb58b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

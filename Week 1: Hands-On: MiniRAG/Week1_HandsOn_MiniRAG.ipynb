{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "023d46d6",
      "metadata": {
        "id": "023d46d6"
      },
      "source": [
        "# CS 5588 — Week 1: Hands-On Lab\n",
        "## Mini-RAG Pipeline: Embeddings → Retrieval → Grounded Generation\n",
        "\n",
        "**Goals:**\n",
        "- Generate semantic embeddings using a Transformer-based encoder\n",
        "- Build a vector index for fast similarity search\n",
        "- Retrieve top-k relevant document chunks\n",
        "- Inject retrieved context into an LLM prompt for grounded generation\n",
        "\n",
        "**Workflow:** GitHub → Colab → Hugging Face → Vector Store (FAISS / Chroma) → LLM\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "121c3a04",
      "metadata": {
        "id": "121c3a04"
      },
      "source": [
        "### GenAI Systems Context (Mini-RAG)\n",
        "This lab implements a **mini Retrieval-Augmented Generation (RAG)** pipeline:\n",
        "- A **Transformer encoder** produces semantic embeddings\n",
        "- A **vector index (FAISS)** enables fast retrieval\n",
        "- Retrieved context is what a downstream **LLM** would use for grounded generation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ef4bef7",
      "metadata": {
        "id": "5ef4bef7"
      },
      "source": [
        "## Step 1 — Environment Setup\n",
        "Install required libraries. This may take ~1 minute.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee7fd505",
      "metadata": {
        "id": "ee7fd505",
        "outputId": "207a2069-ad70-4a77-9ca7-d57add5fc8a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets sentence-transformers faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b733062a",
      "metadata": {
        "id": "b733062a"
      },
      "source": [
        "## Step 2 — Load Dataset & Model from Hugging Face Hub\n",
        "We use a lightweight news dataset and a sentence embedding model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af3f5079",
      "metadata": {
        "id": "af3f5079",
        "outputId": "a0182c20-a7a3-4aad-9199-a98bb3660a6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 200 documents\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "dataset = load_dataset(\"ag_news\", split=\"train[:200]\")\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "texts = dataset[\"text\"]\n",
        "\n",
        "print(f\"Loaded {len(texts)} documents\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "790e6a14",
      "metadata": {
        "id": "790e6a14"
      },
      "source": [
        "## Step 3 — Create Embeddings\n",
        "These vectors represent semantic meaning and enable retrieval before generation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1982665e",
      "metadata": {
        "id": "1982665e",
        "outputId": "37b3c1c2-9485-42e5-b7ff-898b768a3fcd",
        "colab": {
          "referenced_widgets": [
            "83755e592eee4d3dbc16d5c89d7b5435"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83755e592eee4d3dbc16d5c89d7b5435",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding shape: (200, 384)\n"
          ]
        }
      ],
      "source": [
        "embeddings = model.encode(texts, show_progress_bar=True)\n",
        "print('Embedding shape:', embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6911831",
      "metadata": {
        "id": "a6911831"
      },
      "source": [
        "## Step 4 — Build a Vector Index (FAISS)\n",
        "This simulates the retrieval layer in RAG systems.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbca6730",
      "metadata": {
        "id": "bbca6730",
        "outputId": "cda3d889-c953-4a8a-efe8-aca9eb0be732"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index size: 200\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "dim = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "index.add(np.array(embeddings))\n",
        "print('Index size:', index.ntotal)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d8df57f",
      "metadata": {
        "id": "6d8df57f"
      },
      "source": [
        "## Step 5 — Retrieval Function\n",
        "Search for documents related to a query.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "552f1272",
      "metadata": {
        "id": "552f1272"
      },
      "outputs": [],
      "source": [
        "def search(query, k=3):\n",
        "    q_emb = model.encode([query])\n",
        "    distances, indices = index.search(np.array(q_emb), k)\n",
        "    return [texts[int(i)] for i in indices[0]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b37f5c85",
      "metadata": {
        "id": "b37f5c85"
      },
      "source": [
        "## Step 6 — Try It!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "281ea456",
      "metadata": {
        "id": "281ea456",
        "outputId": "4836eb54-0d0d-4d8f-bb49-9dd13ba424a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"U.K.'s NHS taps Gartner to help plan \\\\$9B IT overhaul LONDON -- The U.K.'s National Health Service (NHS) has tapped IT researcher Gartner Inc. to provide market intelligence services as the health organization forges ahead with a mammoth, 5 billion (\\\\$9.2 billion) project to upgrade its information technology infrastructure.\",\n",
              " 'UK Scientists Allowed to Clone Human Embryos (Reuters) Reuters - British scientists said on Wednesday\\\\they had received permission to clone human embryos for medical\\\\research, in what they believe to be the first such license to\\\\be granted in Europe.',\n",
              " 'Coming to The Rescue Got a unique problem? Not to worry: you can find a financial planner for every specialized need']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search(\"artificial intelligence in healthcare\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19e5eb92",
      "metadata": {
        "id": "19e5eb92"
      },
      "source": [
        "## Reflection\n",
        "In 1–2 sentences, explain how embeddings enable retrieval before generation in GenAI systems.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a2OX2kgXeUGB"
      },
      "id": "a2OX2kgXeUGB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "07833156-0731-401f-a51f-31c8084748f4",
      "metadata": {
        "id": "07833156-0731-401f-a51f-31c8084748f4"
      },
      "source": [
        "<span style=\"color: #16ac9f\"> **Embeddings are able to represent textual information in a dense numerical form to encode semantic meaning in a way that allows a system to retrieve relevant information from a set of documents using vector space semantic search rather than keyword-based search. This helps to retrieve specific information that can be used in a generative model to produce correct outputs.**<span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c783cddf-1659-48ab-bbd0-5fa548bb58b9",
      "metadata": {
        "id": "c783cddf-1659-48ab-bbd0-5fa548bb58b9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
